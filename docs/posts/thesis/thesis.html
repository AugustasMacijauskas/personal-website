<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.553">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Augustas Macijauskas">
<meta name="dcterms.date" content="2023-10-04">
<meta name="description" content="Blog post about my master’s research project at the University of Cambridge.">

<title>Augustas Macijauskas - Eliciting latent knowledge from language reward models</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<link href="../../assets/favicon.ico" rel="icon">
<script src="../../site_libs/cookie-consent/cookie-consent.js"></script>
<link href="../../site_libs/cookie-consent/cookie-consent.css" rel="stylesheet">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-1M6C1LWNHY"></script>

<script type="text/plain" cookie-consent="tracking">

window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-1M6C1LWNHY', { 'anonymize_ip': true});
</script>

<script type="text/javascript" charset="UTF-8">
document.addEventListener('DOMContentLoaded', function () {
cookieconsent.run({
  "notice_banner_type":"simple",
  "consent_type":"implied",
  "palette":"light",
  "language":"en",
  "page_load_consent_levels":["strictly-necessary","functionality","tracking","targeting"],
  "notice_banner_reject_button_hide":false,
  "preferences_center_close_button_hide":false,
  "website_name":""
  ,
"language":"en"
  });
});
</script> 
  
<script type="application/json" class="js-hypothesis-config">
{
  "theme": "clean"
}
</script>
<script async="" src="https://hypothes.is/embed.js"></script>
<script>
  window.document.addEventListener("DOMContentLoaded", function (_event) {
    document.body.classList.add('hypothesis-enabled');
  });
</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../../styles.css">
<meta property="og:title" content="Augustas Macijauskas - Eliciting latent knowledge from language reward models">
<meta property="og:description" content="Blog post about my master’s research project at the University of Cambridge.">
<meta property="og:image" content="cambridge.jpg">
<meta property="og:site_name" content="Augustas Macijauskas's blog">
<meta name="twitter:title" content="Augustas Macijauskas - Eliciting latent knowledge from language reward models">
<meta name="twitter:description" content="Blog post about my master’s research project at the University of Cambridge.">
<meta name="twitter:image" content="cambridge.jpg">
<meta name="twitter:creator" content="@augustasmac">
<meta name="twitter:card" content="summary_large_image">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Augustas Macijauskas</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../about.html"> 
<span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../notes.html"> 
<span class="menu-text">Notes</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/AugustasMacijauskas/" target="_blank"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://www.linkedin.com/in/augustas-macijauskas/" target="_blank"> <i class="bi bi-linkedin" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com/augustasmac" target="_blank"> <i class="bi bi-twitter" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
          <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Eliciting latent knowledge from language reward models</h1>
                  <div>
        <div class="description">
          Blog post about my master’s research project at the University of Cambridge.
        </div>
      </div>
                          <div class="quarto-categories">
                <div class="quarto-category">machine learning</div>
                <div class="quarto-category">deep learning</div>
                <div class="quarto-category">LLMs</div>
                <div class="quarto-category">cambridge</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Augustas Macijauskas </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">October 4, 2023</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#eliciting-latent-knowledge-from-language-reward-models" id="toc-eliciting-latent-knowledge-from-language-reward-models" class="nav-link active" data-scroll-target="#eliciting-latent-knowledge-from-language-reward-models">Eliciting latent knowledge from language reward models</a>
  <ul class="collapse">
  <li><a href="#main-steps" id="toc-main-steps" class="nav-link" data-scroll-target="#main-steps">Main steps</a></li>
  <li><a href="#reward-model-training" id="toc-reward-model-training" class="nav-link" data-scroll-target="#reward-model-training">Reward model training</a></li>
  <li><a href="#rl-fine-tuning" id="toc-rl-fine-tuning" class="nav-link" data-scroll-target="#rl-fine-tuning">RL fine-tuning</a></li>
  <li><a href="#conclusion" id="toc-conclusion" class="nav-link" data-scroll-target="#conclusion">Conclusion</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">





<section id="eliciting-latent-knowledge-from-language-reward-models" class="level1">
<h1>Eliciting latent knowledge from language reward models</h1>
<p>Hello, World!</p>
<p>This blog post discusses the main ideas behind my thesis for the MPhil in Machine Learning and Machine Intelligence degree at the University of Cambridge. You can read the full thesis <a href="mlmi-thesis.pdf" target="_blank">here</a>, or check the associated <a href="https://github.com/AugustasMacijauskas/mlmi-thesis" target="_blank">GitHub repository</a>.</p>
<p>The main idea behind the project is trying to build a reward models that reward “truthfulness” in a scalable fashion, which current state-of-the-art methods, such as <em>reinforcement learning from human feedback</em> (RLHF), are not capable of (note that we use quatations because we defined “truthfulness” in a narrow sense and mean only the performance on binary question-aswering tasks, see the thesis pdf for more details). Specifically, methods that <em>discover latent knowledge</em>, such as <a href="https://arxiv.org/abs/2212.03827" target="_blank">CCS</a>, are used to determine whether a piece of input text is truthful or not. Such linear <em>probes</em> are then combined with pre-trained language models to make up reward models, which are used in <em>reinforcement learning</em> RL fine-tuning to improve the “truthfulness” of <em>large language models</em> (LLMs).</p>
<p>These reward models can be trained by using transformed versions of existing datasets, thus relaxing the requirement to collect large numbers of human preference data, as is usual in RLHF. We find that using our reward models along with a few regularization techniques (discussed below) can already be used to improve the “truthfulness” of pre-trained LLMs by <strong>up to 1.6%</strong>, as measured on the TruthfulQA benchmark. Importantly, such an improvement is achieved without sacrificing the models’ performance on more general NLP tasks (we evaluate on the <a href="https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard" target="_blank"><em>Open LLM Leaderboard</em></a> tasks).</p>
<p>Although our method serves as a proof of concept on how hallucinations in LLMs could be tackled in the future, it still has many limitations. For one, the current best DLK methods still have a long way to go in terms of robustness. Moreover, our method only tackles the narrow definition of “truthfulness”, and even though the accuracy on TruthfulQA improves too, many would argue that it is still not a very good proxy for actually reducing levels of hallucination in LLMs. Finally, we found that the pre-trained models that we would fine-tune using RL had to be already quite capable, otherwise our method would not work.</p>
<section id="main-steps" class="level2">
<h2 class="anchored" data-anchor-id="main-steps">Main steps</h2>
<p>There are four main steps to run the method on new data: 1. Split the dataset and prepare it for reward model training and RL fine-tuning. 1. Train a reward model. 1. Performing RL fine-tuning on some pre-trained LLM. 1. Evaluate the fine-tuned LLM on both target and general NLP tasks.</p>
<p>Steps 1 and 4 are mostly boring and you can find more details about them in the README of the GitHub repository, so we are going to focus on the theory and main code bits for steps 2 and 3.</p>
</section>
<section id="reward-model-training" class="level2">
<h2 class="anchored" data-anchor-id="reward-model-training">Reward model training</h2>
<p>As discussed in more detail in chapter 3 of the thesis, the reward model is made up of a pre-trained language model with a probe attached at the end.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="reward_model.png" class="img-fluid figure-img"></p>
<figcaption>The architecture of the reward model</figcaption>
</figure>
</div>
<p>The reward model takes as an input a question <span class="math inline">\(q_i\)</span> with a binary answer (e.g.&nbsp;“Yes”/“No”), creates a contrastive pair from it and then this contrastive pair <span class="math inline">\((x_i^+, x_i^-)\)</span> is used to compute a reward (a number between 0 and 1). The reward is computed by recording activations of the last token in a layer of a language model, denoted <span class="math inline">\(\mathrm{\textbf{emb}}(x_i^+)\)</span> and <span class="math inline">\(\mathrm{\textbf{emb}}(x_i^-)\)</span>. We would try all layers of a language model and pick the one that worked the best. Finally, the embeddings are passed to a logistic classificer which is of the form: <span class="math display">\[p(q_i) = \sigma(\textbf{w}^\mathrm{T}(\mathrm{\textbf{emb}}(x_i^+) - \mathrm{\textbf{emb}}(x_i^-)))\]</span> which is the only module with trainable parameters, the vector <span class="math inline">\(\textbf{w}\)</span>. Here, <span class="math inline">\(\sigma\)</span> is the sigmoid activation function. This output probability denotes the probability that the question <span class="math inline">\(q_i\)</span> is “truthful” which is what we use as the reward.</p>
<p>There are a few other intricacies, such as how to prompt for “truthfulness” (custom prompts are needed), or how to actually find the optimal parameters vector <span class="math inline">\(\textbf{w}\)</span>, but I will sugeest interested readers to refer to the thesis pdf.</p>
</section>
<section id="rl-fine-tuning" class="level2">
<h2 class="anchored" data-anchor-id="rl-fine-tuning">RL fine-tuning</h2>
<p>Once we have a reward model, we can plug into an RL algorithm to perform fine-tuning. We used the <em>proximal policy optimization</em> algorithm, as implement in the <em>Transformer Reinforcement Learning</em> (<a href="https://github.com/huggingface/trl" target="_blank">TRL</a>) library from Hugging Face. We found that a few pieces of regularization had to be applied to stabilize the training process. The tricks are:</p>
<ol type="1">
<li><strong>Prompting</strong> - we found that a specialized prompt had to be devised for each model for the method to work (we mostly focused on the 7B <a href="https://lmsys.org/blog/2023-03-30-vicuna/" target="_blank">Vicuna</a> models).</li>
<li><strong>Maximum number of new tokens</strong> - we found that setting the number of new tokens to two was enough in our case since answers to our binary questions were short. Additionally, we applied output post-processing to strip any undesirable tokens (see the code below).</li>
<li><strong>Encouraging the models to only output in the desired format</strong> - we want the models to only respond with “Yes”/“No”, but even with specialized prompts the models would still sometimes generate different responses. To tackle this, we tweaked the reward to be -1 if the model does not respond in the desired format, and we would give the usual score from the reward model if the output was what the model was asked for. This encouraged the model to converge to only responding with the required format over time.</li>
</ol>
<p>To illustrate these concepts, the finel RL training loop looked roughly like the following:</p>
<div id="cell-6" class="cell" data-vscode="{&quot;languageId&quot;:&quot;plaintext&quot;}">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1"></a><span class="im">import</span> torch</span>
<span id="cb1-2"><a href="#cb1-2"></a><span class="im">import</span> string</span>
<span id="cb1-3"><a href="#cb1-3"></a></span>
<span id="cb1-4"><a href="#cb1-4"></a></span>
<span id="cb1-5"><a href="#cb1-5"></a>CHARACTERS_TO_FILTER <span class="op">=</span> string.punctuation <span class="op">+</span> <span class="st">" </span><span class="ch">\n</span><span class="st">"</span></span>
<span id="cb1-6"><a href="#cb1-6"></a></span>
<span id="cb1-7"><a href="#cb1-7"></a></span>
<span id="cb1-8"><a href="#cb1-8"></a><span class="kw">def</span> is_answer_yes_no(answer):</span>
<span id="cb1-9"><a href="#cb1-9"></a>    <span class="cf">return</span> answer <span class="kw">in</span> [<span class="st">"Yes"</span>, <span class="st">"No"</span>]</span>
<span id="cb1-10"><a href="#cb1-10"></a></span>
<span id="cb1-11"><a href="#cb1-11"></a></span>
<span id="cb1-12"><a href="#cb1-12"></a><span class="kw">def</span> postprocess_response(response):</span>
<span id="cb1-13"><a href="#cb1-13"></a>    <span class="cf">while</span> response <span class="kw">and</span> response[<span class="op">-</span><span class="dv">1</span>] <span class="kw">in</span> CHARACTERS_TO_FILTER:</span>
<span id="cb1-14"><a href="#cb1-14"></a>        response <span class="op">=</span> response[:<span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb1-15"><a href="#cb1-15"></a>    <span class="cf">return</span> response</span>
<span id="cb1-16"><a href="#cb1-16"></a></span>
<span id="cb1-17"><a href="#cb1-17"></a></span>
<span id="cb1-18"><a href="#cb1-18"></a><span class="kw">def</span> train(</span>
<span id="cb1-19"><a href="#cb1-19"></a>    ppo_trainer,</span>
<span id="cb1-20"><a href="#cb1-20"></a>    tokenizer,</span>
<span id="cb1-21"><a href="#cb1-21"></a>    generation_kwargs,</span>
<span id="cb1-22"><a href="#cb1-22"></a>    get_rewards,</span>
<span id="cb1-23"><a href="#cb1-23"></a>    script_args, config,</span>
<span id="cb1-24"><a href="#cb1-24"></a>):</span>
<span id="cb1-25"><a href="#cb1-25"></a>    n_epochs <span class="op">=</span> config.steps <span class="op">//</span> <span class="bu">len</span>(ppo_trainer.dataloader)</span>
<span id="cb1-26"><a href="#cb1-26"></a></span>
<span id="cb1-27"><a href="#cb1-27"></a>    <span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>, n_epochs <span class="op">+</span> <span class="dv">1</span>):</span>
<span id="cb1-28"><a href="#cb1-28"></a>        loop <span class="op">=</span> tqdm(</span>
<span id="cb1-29"><a href="#cb1-29"></a>            <span class="bu">enumerate</span>(ppo_trainer.dataloader, <span class="dv">1</span>),</span>
<span id="cb1-30"><a href="#cb1-30"></a>            total<span class="op">=</span><span class="bu">len</span>(ppo_trainer.dataloader), leave<span class="op">=</span><span class="va">False</span></span>
<span id="cb1-31"><a href="#cb1-31"></a>        )</span>
<span id="cb1-32"><a href="#cb1-32"></a>        <span class="cf">for</span> batch_idx, batch <span class="kw">in</span> loop:</span>
<span id="cb1-33"><a href="#cb1-33"></a>            <span class="co"># Get the input tensors</span></span>
<span id="cb1-34"><a href="#cb1-34"></a>            question_tensors <span class="op">=</span> batch[<span class="st">"input_ids"</span>]</span>
<span id="cb1-35"><a href="#cb1-35"></a></span>
<span id="cb1-36"><a href="#cb1-36"></a>            <span class="co"># Get the generations</span></span>
<span id="cb1-37"><a href="#cb1-37"></a>            response_tensors <span class="op">=</span> ppo_trainer.generate(</span>
<span id="cb1-38"><a href="#cb1-38"></a>                question_tensors,</span>
<span id="cb1-39"><a href="#cb1-39"></a>                return_prompt<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb1-40"><a href="#cb1-40"></a>                batch_size<span class="op">=</span>script_args.generator_batch_size,</span>
<span id="cb1-41"><a href="#cb1-41"></a>                <span class="op">**</span>generation_kwargs,</span>
<span id="cb1-42"><a href="#cb1-42"></a>            )</span>
<span id="cb1-43"><a href="#cb1-43"></a>            responses <span class="op">=</span> tokenizer.batch_decode(</span>
<span id="cb1-44"><a href="#cb1-44"></a>                response_tensors, skip_special_tokens<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb1-45"><a href="#cb1-45"></a>                spaces_between_special_tokens<span class="op">=</span><span class="va">False</span></span>
<span id="cb1-46"><a href="#cb1-46"></a>            )</span>
<span id="cb1-47"><a href="#cb1-47"></a></span>
<span id="cb1-48"><a href="#cb1-48"></a>            <span class="co"># Postprocess the responses</span></span>
<span id="cb1-49"><a href="#cb1-49"></a>            <span class="cf">if</span> script_args.postprocess_responses:</span>
<span id="cb1-50"><a href="#cb1-50"></a>                responses <span class="op">=</span> [postprocess_response(x) <span class="cf">for</span> x <span class="kw">in</span> responses]</span>
<span id="cb1-51"><a href="#cb1-51"></a>            batch[<span class="st">"response"</span>] <span class="op">=</span> responses</span>
<span id="cb1-52"><a href="#cb1-52"></a></span>
<span id="cb1-53"><a href="#cb1-53"></a>            <span class="co"># Compute the rewards (scores)</span></span>
<span id="cb1-54"><a href="#cb1-54"></a>            texts <span class="op">=</span> [q <span class="op">+</span> <span class="st">" "</span> <span class="op">+</span> r <span class="cf">for</span> q, r <span class="kw">in</span> <span class="bu">zip</span>(batch[<span class="st">"query"</span>], batch[<span class="st">"response"</span>])]</span>
<span id="cb1-55"><a href="#cb1-55"></a>            rewards <span class="op">=</span> get_rewards(texts)</span>
<span id="cb1-56"><a href="#cb1-56"></a></span>
<span id="cb1-57"><a href="#cb1-57"></a>            <span class="co"># Replace reward for undesired answers to -1</span></span>
<span id="cb1-58"><a href="#cb1-58"></a>            mask <span class="op">=</span> [<span class="kw">not</span> is_answer_yes_no(x) <span class="cf">for</span> x <span class="kw">in</span> batch[<span class="st">"response"</span>]]</span>
<span id="cb1-59"><a href="#cb1-59"></a>            mask <span class="op">=</span> torch.tensor(mask, dtype<span class="op">=</span>torch.<span class="bu">bool</span>) <span class="co"># cast to tensor</span></span>
<span id="cb1-60"><a href="#cb1-60"></a>            rewards[mask] <span class="op">=</span> <span class="op">-</span><span class="dv">1</span></span>
<span id="cb1-61"><a href="#cb1-61"></a></span>
<span id="cb1-62"><a href="#cb1-62"></a>            <span class="co"># Make the rewards a list of tensors</span></span>
<span id="cb1-63"><a href="#cb1-63"></a>            rewards <span class="op">=</span> [x <span class="cf">for</span> x <span class="kw">in</span> rewards]</span>
<span id="cb1-64"><a href="#cb1-64"></a></span>
<span id="cb1-65"><a href="#cb1-65"></a>            <span class="co"># Run PPO step</span></span>
<span id="cb1-66"><a href="#cb1-66"></a>            stats <span class="op">=</span> ppo_trainer.step(question_tensors, response_tensors, rewards)</span>
<span id="cb1-67"><a href="#cb1-67"></a>            ppo_trainer.log_stats(stats, batch, rewards)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>And the <code>generation_kwargs</code> look like the following:</p>
<div id="cell-8" class="cell" data-vscode="{&quot;languageId&quot;:&quot;plaintext&quot;}">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1"></a>generation_kwargs <span class="op">=</span> {</span>
<span id="cb2-2"><a href="#cb2-2"></a>    <span class="st">"top_k"</span>: <span class="dv">0</span>,</span>
<span id="cb2-3"><a href="#cb2-3"></a>    <span class="st">"top_p"</span>: <span class="fl">1.0</span>,</span>
<span id="cb2-4"><a href="#cb2-4"></a>    <span class="st">"do_sample"</span>: <span class="va">True</span>,</span>
<span id="cb2-5"><a href="#cb2-5"></a>    <span class="st">"pad_token_id"</span>: tokenizer.pad_token_id,</span>
<span id="cb2-6"><a href="#cb2-6"></a>    <span class="st">"eos_token_id"</span>: <span class="dv">100_000</span>,</span>
<span id="cb2-7"><a href="#cb2-7"></a>    <span class="st">"pad_to_multiple_of"</span>: <span class="dv">8</span>,</span>
<span id="cb2-8"><a href="#cb2-8"></a>    <span class="st">"max_new_tokens"</span>: <span class="dv">2</span>,</span>
<span id="cb2-9"><a href="#cb2-9"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<p>I hope you found this blog as interesting as it was for me to work on this project. I feel like I have learnt a lot during it, for example, I joined multiple ML communities and got involved in discussions with very smart and ambitious people. Perhaps my proudest achievement is making my first open-source contribution to the <code>elk</code> library (<a href="https://github.com/EleutherAI/elk" target="_blank">link</a>), as well as reported multiple bugs to the <em>big-refactor</em> branch of <em>Language Model Evaluation Harness</em> (<a href="https://github.com/EleutherAI/lm-evaluation-harness/tree/big-refactor" target="_blank">link</a>).</p>
<p>I am excited to dive deeper into LLMs-related topics in the future. Feel free to reach out if you have any opportunities on offer!</p>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
      &nbsp;
    </div>   
    <div class="nav-footer-center">

<div class="cookie-consent-footer"><a href="#" id="open_preferences_center">Cookie Preferences</a></div></div>
    <div class="nav-footer-right">
      &nbsp;
    </div>
  </div>
</footer>




</body></html>