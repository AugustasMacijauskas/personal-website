{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: Elegant implementation of Naive Bayes in just 10 lines of code\n",
    "author: Augustas Macijauskas\n",
    "description: A tutorial on how to use a few tricks to implement a Naive Bayes model in just a few lines of code.\n",
    "date: \"2021/02/01\"\n",
    "image: bayes-formula.jpg\n",
    "image-alt: Bayes' theorem\n",
    "toc: true\n",
    "categories: [machine-learning, nlp]\n",
    "draft: false\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TLDR\n",
    "\n",
    "This article is adapted from [fast.ai](https://www.fast.ai/)'s *Machine Learning for Coders* course, specifically, [lesson 10](https://course18.fast.ai/lessonsml1/lesson10.html). I would highly recommend checking this and other courses from fast.ai, it has numerous tips on how to do practical machine learning and deep learning.\n",
    "\n",
    "We will be building a naive Bayes classifier in just **10 lines** of code that will get over **98%** accuracy on a spam message filtering task.\n",
    "\n",
    "We will do this in the top-bottom approach, where we will first build the model and then dig deeper into the theory of how it works."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports\n",
    "\n",
    "Toggle cells below if you want to see what imports are being made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|code-fold: true\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "We are going to use a dataset with 5572 messages in it. Unfortunately, I am unable to provide full access to this dataset, so you'll have to take my word for what the contents of the dataset are.\n",
    "\n",
    "Label of `0` means the message is not spam, and `1` means it is spam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>Will Ì_ b going to esplanade fr home?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                message  label\n",
       "0     Go until jurong point, crazy.. Available only ...      0\n",
       "1                         Ok lar... Joking wif u oni...      0\n",
       "2     Free entry in 2 a wkly comp to win FA Cup fina...      1\n",
       "3     U dun say so early hor... U c already then say...      0\n",
       "4     Nah I don't think he goes to usf, he lives aro...      0\n",
       "...                                                 ...    ...\n",
       "5567  This is the 2nd time we have tried 2 contact u...      1\n",
       "5568              Will Ì_ b going to esplanade fr home?      0\n",
       "5569  Pity, * was in mood for that. So...any other s...      0\n",
       "5570  The guy did some bitching but I acted like i'd...      0\n",
       "5571                         Rofl. Its true to its name      0\n",
       "\n",
       "[5572 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|echo: false\n",
    "df = pd.read_csv(\"data/spam_email_data.csv\", encoding=\"latin-1\")\n",
    "df.drop(columns=[\"Unnamed: 2\", \"Unnamed: 3\", \"Unnamed: 4\"], inplace=True)\n",
    "df = df.rename(columns={ \"v1\": \"class\", \"v2\": \"message\" })\n",
    "df[\"label\"] = df[\"class\"] == \"spam\"\n",
    "df.drop(columns=[\"class\"], inplace=True)\n",
    "df[\"label\"] = df[\"label\"].astype(np.int8)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The numbers of non-spam and spam messages are respectively:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4825, 747)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|echo: false\n",
    "(df[\"label\"] == 0).sum(), (df[\"label\"] == 1).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example spam message is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|echo: false\n",
    "df[\"message\"][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's split the data into train and test sets with 20% of data going into the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.8\n",
    "train_length = int(len(df) * train_ratio)\n",
    "X_train = np.squeeze(df.drop(columns=[\"label\"])[:train_length].values)\n",
    "y_train = df[\"label\"][:train_length].values\n",
    "X_val = np.squeeze(df.drop(columns=[\"label\"])[train_length:].values)\n",
    "y_val = df[\"label\"][train_length:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 5572)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|include: false\n",
    "len(X_train) + len(X_val), len(y_train) + len(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4457,),\n",
       " array(['Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat... until ',\n",
       "        'Ok lar... Joking wif u oni...',\n",
       "        \"Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\",\n",
       "        ...,\n",
       "        'Storming msg: Wen u lift d phne, u say \\\\HELLO\\\\\" Do u knw wt is d real meaning of HELLO?? . . . It\\'s d name of a girl..! . . . Yes.. And u knw who is dat girl?? \\\\\"Margaret Hello\\\\\" She is d girlfrnd f Grahmbell who invnted telphone... . . . . Moral:One can 4get d name of a person',\n",
       "        'If you want to mapquest it or something look up \\\\usf dogwood drive\\\\\"',\n",
       "        'Aight should I just plan to come up later tonight?'], dtype=object))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|include: false\n",
    "X_train.shape, X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|include: false\n",
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.1350684316805026, 0.13004484304932734)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|include: false\n",
    "y_train.mean(), y_val.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4457,), (1115,))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|include: false\n",
    "y_train.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the model\n",
    "\n",
    "Below I am going to provide the code for the model without too much explanation, and then in the next section I'll discuss what is happening under the hood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(max_df=0.1)\n",
    "train_term_doc = vectorizer.fit_transform(X_train)\n",
    "val_term_doc = vectorizer.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|include: false\n",
    "count = 0\n",
    "for msg in X_train:\n",
    "    count += int(\"unknown\" in msg)\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7147"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|include: false\n",
    "vectorizer.vocabulary_[\"unknown\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7740"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|include: false\n",
    "len(vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4457, 7740)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|include: false\n",
    "train_term_doc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<4457x7740 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 51133 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|include: false\n",
    "train_term_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x7740 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 17 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|include: false\n",
    "train_term_doc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|include: false\n",
    "len(vectorizer.stop_words_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'and', 'for', 'in', 'is', 'it', 'me', 'my', 'of', 'the', 'to', 'you', 'your'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|include: false\n",
    "vectorizer.stop_words_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7740, ['correction', 'corrupt', 'corvettes', 'cos', 'cosign'])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|include: false\n",
    "vocab = vectorizer.get_feature_names()\n",
    "len(vocab), vocab[2000:2005]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[11, 26,  1, ...,  2,  1,  1]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|include: false\n",
    "train_term_doc[y_train == 1].sum(0) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, ..., 0, 0, 0], dtype=int8)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|include: false\n",
    "len(y_train == 1) / len(y_train == 0)\n",
    "len(y_train == 1)\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[68,\n",
       " 348,\n",
       " 356,\n",
       " 674,\n",
       " 1000,\n",
       " 1903,\n",
       " 2102,\n",
       " 2613,\n",
       " 2739,\n",
       " 2848,\n",
       " 2981,\n",
       " 4398,\n",
       " 5520,\n",
       " 5568,\n",
       " 5614,\n",
       " 6452,\n",
       " 6771,\n",
       " 6907,\n",
       " 7075,\n",
       " 7497,\n",
       " 7538]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|include: false\n",
    "train_term_doc.tolil().rows[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21,\n",
       " array(['08452810075over18', '2005', '21st', '87121', 'apply', 'comp',\n",
       "        'cup', 'entry', 'fa', 'final', 'free', 'may', 'question', 'rate',\n",
       "        'receive', 'std', 'text', 'tkts', 'txt', 'win', 'wkly'],\n",
       "       dtype='<U34'))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|include: false\n",
    "feats = np.array(vectorizer.get_feature_names())[train_term_doc.tolil().rows[2]]\n",
    "len(feats), feats\n",
    "# type(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28,\n",
       " \"Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|include: false\n",
    "len(X_train[2].split(\" \")), X_train[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what our example spam message got turned into:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "has become:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'free entry wkly comp win fa cup final tkts 21st may 2005 text fa 87121 receive entry question std txt rate apply 08452810075over18'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|echo: false\n",
    "out = \"free entry wkly comp win fa cup final tkts 21st may 2005 text fa 87121 receive entry question std txt rate apply 08452810075over18\"\n",
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, some words did not make it into the vocabulary because they were too common (e.g. the word \"in\"), and punctuation and apostrophes were also left out. This is **not** ideal and it would probably be a good idea to try a better tokenizer, and although we won't do that here, you can try finding one yourself. A good place to start would be [here](https://docs.fast.ai/text.core.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'free': 1,\n",
       "         'entry': 2,\n",
       "         'wkly': 1,\n",
       "         'comp': 1,\n",
       "         'win': 1,\n",
       "         'fa': 2,\n",
       "         'cup': 1,\n",
       "         'final': 1,\n",
       "         'tkts': 1,\n",
       "         '21st': 1,\n",
       "         'may': 1,\n",
       "         '2005': 1,\n",
       "         'text': 1,\n",
       "         '87121': 1,\n",
       "         'receive': 1,\n",
       "         'question': 1,\n",
       "         'std': 1,\n",
       "         'txt': 1,\n",
       "         'rate': 1,\n",
       "         'apply': 1,\n",
       "         '08452810075over18': 1})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|include: false\n",
    "from collections import Counter\n",
    "Counter(out.split(\" \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we we'll be using Bayes' theorem, note that here `p` stands for **probability of features given spam**, `q` stands for **probability of features given non-spam**, and `b` encodes the **probabilities that a document is of a certain class** (or what Bayesians call *priors*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = train_term_doc[y_train == 1].sum(0) + 1\n",
    "q = train_term_doc[y_train == 0].sum(0) + 1\n",
    "ratio = np.log((p / p.sum()) / (q / q.sum()))\n",
    "b = np.log((y_train == 1).sum() / (y_train == 0).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1, 7740), matrix([[11, 26,  1, ...,  2,  1,  1]]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|include: false\n",
    "p.shape, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1, 7740), matrix([[1, 1, 2, ..., 1, 9, 2]]))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|include: false\n",
    "q.shape, q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1, 7740),\n",
       " matrix([[ 3.30174677,  4.16194804,  0.21070432, ...,  1.59699868,\n",
       "          -1.29337308,  0.21070432]]))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|include: false\n",
    "ratio.shape, ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((), -1.856868840688609)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|include: false\n",
    "b.shape, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1115, 1)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|include: false\n",
    "(val_term_doc @ ratio.T).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check what the accuracy is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9856502242152466"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_preds = val_term_doc @ ratio.T + b\n",
    "preds = pre_preds.T > 0\n",
    "(preds == y_val).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1115)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|include: false\n",
    "(preds == y_val).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! We got over 98% accuracy, and even though this dataset is not particularly hard, I think it is cool that we managed to do it in just 10 lines of code. Let's check confusion matrices too:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1, 1115), (1, 1115))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|include: false\n",
    "y_val.reshape(preds.shape).shape, preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1, 1115), matrix([[False]]))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|include: false\n",
    "y_val.reshape(preds.shape).shape, preds[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "145"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|include: false\n",
    "(y_val == 1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[962,   8],\n",
       "       [  8, 137]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|echo: false\n",
    "confusion_matrix(y_val, preds.T, normalize=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.99175258, 0.00824742],\n",
       "       [0.05517241, 0.94482759]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|echo: false\n",
    "confusion_matrix(y_val, preds.T, normalize=\"true\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the model is slightly less accurate on spam messages, just over 94%, which means that if we used this model in real life, it would let some spam messages slip through. Regardless, it's doing a great job overall. Let's now try to understand the inner workings of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9820627802690582"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|include: false\n",
    "pre_preds = val_term_doc.sign() @ ratio.T + b\n",
    "preds = pre_preds.T > 0\n",
    "(preds == y_val).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9820627802690582"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|include: false\n",
    "m = LogisticRegression()\n",
    "m.fit(train_term_doc, y_train)\n",
    "preds = m.predict(val_term_doc)\n",
    "(preds == y_val).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9820627802690582"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|include: false\n",
    "m = LogisticRegression()\n",
    "m.fit(train_term_doc.sign(), y_train)\n",
    "preds = m.predict(val_term_doc.sign())\n",
    "(preds == y_val).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What just happened?!?\n",
    "\n",
    "As you can see, our naive Bayes classifier got over 98% accuracy on this dataset in just 10 lines of code. But how does it actually work? Let's look at everything piece by piece."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. The `CountVectorizer`\n",
    "\n",
    "Naive Bayes classifier uses what is called a **bag of words** approach. It simply means that we disregard any relationships between words and just look at how often they appear in the text that we want to classify.\n",
    "\n",
    "> Note: I am not saying that *bag of words* is the best approach to do NLP, it is usually quite the opposite as nowadays we have tools like RNNs and Transformers that perform much better on NLP tasks. However, we use it here because it is a really simple approach that sometimes still gives reasonable results, as it did in this case!\n",
    "\n",
    "\n",
    "This is exactly what we use a `CountVectorizer` for: it produces a **term document matrix** with frequencies of each word for each message.\n",
    "\n",
    "Let's look at an example of what [sklearn's `CountVectorizer`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html) is doing. Suppose that our messages are:\n",
    "\n",
    "|message|label|\n",
    "|-|-|\n",
    "|This is a good message|0|\n",
    "|A good message|0|\n",
    "|This message is bad|1|\n",
    "|The message is bad|1|\n",
    "\n",
    "Then, what a `CountVectorizer` is going to do for us is produce the following matrix:\n",
    "\n",
    "|message|label|this|is|a|good|message|the|bad|\n",
    "|-|-|-|-|-|-|-|-|-|\n",
    "|This is a good message|0|1|1|1|1|1|0|0|\n",
    "|A good message|0|0|0|1|1|1|0|0|\n",
    "|This message is bad|1|1|1|0|0|1|0|1|\n",
    "|The message is bad|1|0|1|0|0|1|1|1|\n",
    "\n",
    "> Important: `CountVectorizer` just finds the *vocabulary* (list of all the unique words in our data) and then counts how often each word from the vocabulary is found in each message.\n",
    "\n",
    "\n",
    "Notice that for a larger dataset, our vocabulary might become very large which would mean that most of the cells in our term document matrix would be `0`. For this reason, the sklearn implementation actually produces a **sparse matrix** which, instead of storing all the entries, stores only the location and values of non-zero entries, and since there are only so many of them, saves huge amounts of memory. How neat!\n",
    "\n",
    "You must have noticed that I used a `max_df=0.1` parameter for my `CountVectorizer`. This tells the vectorizer to **ignore** any words that appear in more than `10%` on the documents as we can safely say that they are **too common**. I came with this number by trying different values and looking at `vectorizer.stop_words_` to check how many and which words were ignored until I was satisfied. When you build your own model, make sure to play around with this and other parameters, such as `min_df` (opposite of `max_df`, used for very rare words), to find what works best for you! You can find more information on what parameters for `CountVectorizer` can be tinkered on the official docs.\n",
    "\n",
    "A trick that we want to do before moving on is to note that later we will want to calculate probabilities of each word appearing in spam or non-spam messages. But it might happen that certain words do not appear in a particular class at all and we might run into trouble because we will get feature probabilities of zero, and we don't want that. To counter that, we will add a row of ones, like so:\n",
    "\n",
    "|message|label|this|is|a|good|message|the|bad|\n",
    "|-|-|-|-|-|-|-|-|-|\n",
    "|This is a good message|0|1|1|1|1|1|0|0|\n",
    "|A good message|0|0|0|1|1|1|0|0|\n",
    "|This message is bad|1|1|1|0|0|1|0|1|\n",
    "|The message is bad|1|0|1|0|0|1|1|1|\n",
    "|*row of ones*||1|1|1|1|1|1|1|\n",
    "\n",
    "If we think more about, adding a row of ones is not that counter-intuitive at all, since the messages that we have so far only carry information up to this point in time, but if a word has not appeared in any of the messages so far, it is not at all impossible that it will not appear in the future, so adding the extra one takes care of that for us.\n",
    "\n",
    "So that our feature probabilities will be:\n",
    "\n",
    "|message|label|this|is|a|good|message|the|bad|\n",
    "|-|-|-|-|-|-|-|-|-|\n",
    "|This is a good message|0|1|1|1|1|1|0|0|\n",
    "|A good message|0|0|0|1|1|1|0|0|\n",
    "|This message is bad|1|1|1|0|0|1|0|1|\n",
    "|The message is bad|1|0|1|0|0|1|1|1|\n",
    "|*row of ones*||1|1|1|1|1|1|1|\n",
    "|**P(feature\\|0)**||0.67|0.67|1|1|1|0.33|0.33|\n",
    "|**P(feature\\|1)**||0.67|1|0.33|0.33|1|0.67|1|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a vectorizer object that will ignore any\n",
    "# words that appear in more than 10% of messages.\n",
    "vectorizer = CountVectorizer(max_df=0.1)\n",
    "\n",
    "# Use the fit_transform method of the vectorizer to get\n",
    "# the term document matrix for the training set.\n",
    "train_term_doc = vectorizer.fit_transform(X_train)\n",
    "\n",
    "# Use the transform method of the vectorizer to get\n",
    "# the term document matrix for the validation set.\n",
    "# We do it this way so that train and validation sets\n",
    "# are have the same vocabularies so that we could make predictions.\n",
    "val_term_doc = vectorizer.transform(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Bayes' theorem\n",
    "\n",
    "Now, we can get to the essence of the model which is to apply [Bayes' theorem](https://en.wikipedia.org/wiki/Bayes%27_theorem). I am not going to give the usual form of the formula, but instead one that will illustrate how we will be using it. Our goal is, given a particular message, figure out whether it is spam or not. Hence, the formula for us is going to take the form:\n",
    "\n",
    "$P(\\text{spam} \\mid \\text{message}) = \\frac{P(\\text{message} \\mid \\text{spam}) \\cdot P(\\text{spam})}{P(\\text{message})}$\n",
    "\n",
    "But we can use a trick: instead of trying to predict whether it is spam or not, let's look at which class is a message more likely, i.e. $\\frac{P(\\text{spam} \\mid \\text{message})}{P(\\text{non-spam} \\mid \\text{message})}$. In that case, the formula will become:\n",
    "\n",
    "$\\text{ratio} = \\frac{P(\\text{spam} \\mid \\text{message})}{P(\\text{non-spam} \\mid \\text{message})} = \\frac{P(\\text{message} \\mid \\text{spam}) \\cdot P(\\text{spam})}{P(\\text{message} \\mid \\text{non-spam}) \\cdot P(\\text{non-spam})}$\n",
    "\n",
    "Referring to our previous example, the ratios would then be:\n",
    "\n",
    "|message|label|this|is|a|good|message|the|bad|\n",
    "|-|-|-|-|-|-|-|-|-|\n",
    "|This is a good message|0|1|1|1|1|1|0|0|\n",
    "|A good message|0|0|0|1|1|1|0|0|\n",
    "|This message is bad|1|1|1|0|0|1|0|1|\n",
    "|The message is bad|1|0|1|0|0|1|1|1|\n",
    "|*row of ones*||1|1|1|1|1|1|1|\n",
    "|**P(feature\\|0)**||0.67|0.67|1|1|1|0.33|0.33|\n",
    "|**P(feature\\|1)**||0.67|1|0.33|0.33|1|0.67|1|\n",
    "|**ratio**||1|1.5|0.33|0.33|1|2|3|\n",
    "\n",
    "> Important: As you can see, ratios are greater than 1 for features that are more likely to be in spam messages and lower than one otherwise.\n",
    "\n",
    "\n",
    "Then, to further simplify things, we make the **naive** Bayes assumption, which says that probability of any word appearing in a message is independent of probabilities of other words appearing in that same message.\n",
    "\n",
    "> Note: Obviously, this is a **very** naive assumption and that is most certainly not the case, but it turns out to work quite well.\n",
    "\n",
    "\n",
    "Under the naive assumption, the probabilities like $P(\\text{message} \\mid \\text{spam})$ can be factorized into a product of probabilities of individual features appearing in a message, so that:\n",
    "\n",
    "$P(\\text{message} \\mid \\text{spam}) = \\prod_{i=1}^{n}{P(\\text{features[i]} \\mid \\text{spam})}$\n",
    "\n",
    "\n",
    "and similarly for $P(\\text{message} \\mid \\text{non-spam})$. Then, our big formula becomes:\n",
    "\n",
    "$\\text{ratio} = \\frac{P(\\text{spam} \\mid \\text{message})}{P(\\text{non-spam} \\mid \\text{message})} = \\frac{\\prod_{i=1}^{n}{P(\\text{features[i]} \\mid \\text{spam})}}{\\prod_{i=1}^{n}{P(\\text{features[i]} \\mid \\text{non-spam})}} \\cdot \\frac{P(\\text{spam})}{P(\\text{non-spam})}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. A few final tricks\n",
    "\n",
    "We are almost done, now we just want to apply a few tricks to make our calculations easier. First, notice that multiplying lots of probabilities together is going to result into a very small number and we might run out of floating point precision, so we can take the **natural logarithm** instead to handle this. Note that in this case we compare ratios not with `1`, but with `0` (because `log(1)=0`) and that by the properties of logarithms all the products are going to turn into sums, which makes everything even simpler!\n",
    "\n",
    "Finally, we notice that to make predictions, we can just perform matrix multiplication on the **validation term document matrix** and our derived vector of ratios and add (remember, we are in log space!) the ratio of priors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Putting it all together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9856502242152466"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Calculate P(feature|1) and P(feature|0).\n",
    "# This plus ones are there to constitute the\n",
    "# row of ones discussed above\n",
    "p = train_term_doc[y_train == 1].sum(0) + 1\n",
    "q = train_term_doc[y_train == 0].sum(0) + 1\n",
    "\n",
    "# Calculate the ratios according to our derived formulae\n",
    "ratio = np.log((p / p.sum()) / (q / q.sum()))\n",
    "\n",
    "# Calculate the log of ratio of priors\n",
    "b = np.log((y_train == 1).sum() / (y_train == 0).sum())\n",
    "\n",
    "# Make some predictions on the validation set\n",
    "pre_preds = val_term_doc @ ratio.T + b\n",
    "preds = pre_preds.T > 0 # Greater than 0 because we are working in log space\n",
    "(preds == y_val).mean() # Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How could I use this?\n",
    "\n",
    "With this newly acquired knowledge, you can go ahead and try using this model on your own NLP data! Though I have to warn you: the dataset used in this article was quite easy and naive Bayes classifier might not work as good for your data. But it is well-worth trying it out, especially when you can build one in just 10 lines of code!\n",
    "\n",
    "To better understand the materials of this article make sure to play around with anything that you want to dig deeper into, e.g. the different parameters and attributes of `CountVectorizer`. You can also check the full version of this on GitHub to see what cells I ran myself to better understand the inner working of this model.  \n",
    "\n",
    "If you were to try and run your own model, a few suggestions for improving the models performance are presented below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try n-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(ngram_range=(1, 3), max_df=0.1)\n",
    "train_term_doc = vectorizer.fit_transform(X_train)\n",
    "val_term_doc = vectorizer.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4457, 87753)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|include: false\n",
    "train_term_doc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = train_term_doc[y_train == 1].sum(0) + 1\n",
    "q = train_term_doc[y_train == 0].sum(0) + 1\n",
    "ratio = np.log((p / p.sum()) / (q / q.sum()))\n",
    "b = np.log((y_train == 1).sum() / (y_train == 0).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(87753, 1)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|include: false\n",
    "val_term_doc.shape\n",
    "ratio.T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9874439461883409"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_preds = val_term_doc @ ratio.T + b\n",
    "preds = pre_preds.T > 0\n",
    "(preds == y_val).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turns out the model gives even better accuracy with bigrams and trigrams included. But watch out! Checking the confusion matrices, we see that the model is now perfect on non-spam messages, but the error on spam messages has increased. This might not be what we want, so we have to be careful with interpreting our models!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[968,   2],\n",
       "       [ 12, 133]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_val, preds.T, normalize=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.99793814, 0.00206186],\n",
       "       [0.08275862, 0.91724138]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_val, preds.T, normalize=\"true\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binarized version\n",
    "\n",
    "You can also try the binarized version of the term document matrix (i.e. instead of frequencies we look at whether a word is present or not)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9874439461883409"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_preds = val_term_doc.sign() @ ratio.T + b\n",
    "preds = pre_preds.T > 0\n",
    "(preds == y_val).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning the parameters with logistic regression\n",
    "\n",
    "Finally, you might try taking it to the next level and **learning** the parameters with a logistic regression instead of using the theoretical ones. Check the parameters `C` for regularization and `dual=True` for when you term document matrix is *much* wider than it is tall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9811659192825112"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = LogisticRegression(C=1e1, dual=False)\n",
    "m.fit(train_term_doc, y_train)\n",
    "preds = m.predict(val_term_doc)\n",
    "(preds == y_val).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9802690582959641"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Binarized version\n",
    "m = LogisticRegression(C=1e1, dual=False)\n",
    "m.fit(train_term_doc.sign(), y_train)\n",
    "preds = m.predict(val_term_doc.sign())\n",
    "(preds == y_val).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've managed to build a fast and considerably accurate naive Bayes model in just 10 lines of code. We've also discussed some ways for how it could be improved and adapted to your own problems, e.g. using n-grams, trying the binarized version or employing a logistic regression to learn the parameters.\n",
    "\n",
    "It turns out that the best linear model that we can build (i.e. not involving RNNs or transformer) is actually a combination of naive Bayes and logistic regression, but that that is something for another time, although you can check [this](https://course18.fast.ai/lessonsml1/lesson11.html) lesson from fast.ai if you want to find out more yourself."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
